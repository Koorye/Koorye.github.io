<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/blog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/blog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/blog/css/main.css">


<link rel="stylesheet" href="/blog/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"koorye.github.io","root":"/blog/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="小样本学习中局部特征学习非常重要，因为在有限的样本中，局部特征能够更好地捕捉样本的细节信息，从而提高模型的泛化能力。本文总结了小样本学习中局部特征学习的方法，包括局部特征匹配和局部特征融合两大类方法。">
<meta property="og:type" content="article">
<meta property="og:title" content="小样本学习中的局部特征学习方法">
<meta property="og:url" content="https://koorye.github.io/blog/2023/09/11/2023-09-11%20How%20to%20Use%20Region%20Features%20in%20Few-shot%20Learning/index.html">
<meta property="og:site_name" content="吴世涵的博客">
<meta property="og:description" content="小样本学习中局部特征学习非常重要，因为在有限的样本中，局部特征能够更好地捕捉样本的细节信息，从而提高模型的泛化能力。本文总结了小样本学习中局部特征学习的方法，包括局部特征匹配和局部特征融合两大类方法。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/Koorye/my-images/master/img/202309110912192.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Koorye/my-images/master/img/202309110918322.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Koorye/my-images/master/img/202309110923071.png">
<meta property="og:image" content="https://s2.loli.net/2023/09/12/Qe32LHjYgJVONfo.jpg">
<meta property="og:image" content="https://s2.loli.net/2023/09/12/WmaKnirYEJb49PN.jpg">
<meta property="og:image" content="https://s2.loli.net/2023/09/12/ZOjdXBJMTLE7AfW.jpg">
<meta property="og:image" content="https://s2.loli.net/2023/09/12/6zG5RmO1e7nCbwv.jpg">
<meta property="og:image" content="https://s2.loli.net/2023/09/12/4MzwktVx57Q86eA.jpg">
<meta property="og:image" content="https://s2.loli.net/2023/09/12/HZVU5Qx6Fti4Bru.jpg">
<meta property="og:image" content="https://s2.loli.net/2023/09/13/Sx1h8lIpE5rjmUK.jpg">
<meta property="og:image" content="https://raw.githubusercontent.com/Koorye/my-images/master/img/202309110930005.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Koorye/my-images/master/img/202309110932170.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Koorye/my-images/master/img/202309110936755.png">
<meta property="og:image" content="https://s2.loli.net/2023/09/12/i7YrZ28T64akH9g.jpg">
<meta property="og:image" content="https://s2.loli.net/2023/09/12/VCxve6X8y3I4gqP.jpg">
<meta property="og:image" content="https://s2.loli.net/2023/09/12/lLqcfej2KHTvIwQ.jpg">
<meta property="og:image" content="https://s2.loli.net/2023/09/12/gvhWBym3nRQ9NLT.jpg">
<meta property="og:image" content="https://s2.loli.net/2023/09/12/1fltvN5suihwQTa.jpg">
<meta property="og:image" content="https://s2.loli.net/2023/09/12/nftURovFOjKWec8.jpg">
<meta property="og:image" content="https://s2.loli.net/2023/09/12/rax18qOQ4UAmVSf.jpg">
<meta property="og:image" content="https://s2.loli.net/2023/09/13/bERlLcf2PrM5IYh.jpg">
<meta property="og:image" content="https://s2.loli.net/2023/09/13/FSB4ucNlwLM6YIR.jpg">
<meta property="og:image" content="https://s2.loli.net/2023/09/13/orRwxMdVfIazjuW.jpg">
<meta property="og:image" content="https://s2.loli.net/2023/09/13/3YGj6LqMdHuNPIc.jpg">
<meta property="og:image" content="https://s2.loli.net/2023/09/13/qY3OW1wQ9z64JVa.jpg">
<meta property="og:image" content="https://s2.loli.net/2023/09/13/adqbSX5xmv8UugT.jpg">
<meta property="og:image" content="https://s2.loli.net/2023/09/13/IelVBM5vhTpwYUC.jpg">
<meta property="article:published_time" content="2023-09-11T11:47:00.000Z">
<meta property="article:modified_time" content="2025-03-06T08:25:05.087Z">
<meta property="article:author" content="吴世涵">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="小样本学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/Koorye/my-images/master/img/202309110912192.png">

<link rel="canonical" href="https://koorye.github.io/blog/2023/09/11/2023-09-11%20How%20to%20Use%20Region%20Features%20in%20Few-shot%20Learning/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>小样本学习中的局部特征学习方法 | 吴世涵的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/blog/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">吴世涵的博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/blog/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/blog/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/blog/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/blog/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/blog/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://koorye.github.io/blog/2023/09/11/2023-09-11%20How%20to%20Use%20Region%20Features%20in%20Few-shot%20Learning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/images/avatar.jpg">
      <meta itemprop="name" content="吴世涵">
      <meta itemprop="description" content="来自电子科技大学(UESTC)计算机科学与工程学院的硕士研究生">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="吴世涵的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          小样本学习中的局部特征学习方法
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-09-11 19:47:00" itemprop="dateCreated datePublished" datetime="2023-09-11T19:47:00+08:00">2023-09-11</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/blog/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>3k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>3 分钟</span>
            </span>
            <div class="post-description">小样本学习中局部特征学习非常重要，因为在有限的样本中，局部特征能够更好地捕捉样本的细节信息，从而提高模型的泛化能力。本文总结了小样本学习中局部特征学习的方法，包括局部特征匹配和局部特征融合两大类方法。</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="方法">方法</h1>
<h2 id="局部特征匹配">局部特征匹配</h2>
<h3 id="few-shot-image-classification">Few-shot Image
Classification</h3>
<h4 id="deepbdc-cvpr-2022">DeepBDC (CVPR 2022)</h4>
<p>采用BDC距离衡量局部特征，具体来说，特征可选择在空间或通道维度进行两两相似度计算，之后作行、列归一化和开方得到BDC矩阵，并计算BDC矩阵的相似度作为度量。</p>
<figure>
<img src="https://raw.githubusercontent.com/Koorye/my-images/master/img/202309110912192.png" alt="image.png">
<figcaption aria-hidden="true">image.png</figcaption>
</figure>
<h4 id="deepemd-cvpr-2020">DeepEMD (CVPR 2020)</h4>
<p>计算局部特征的最优化传输距离作为度量。</p>
<p><img src="https://raw.githubusercontent.com/Koorye/my-images/master/img/202309110918322.png" alt="image.png"> #### Dense Classification (CVPR 2019)
对特征的每个region单独进行分类后融合分数。</p>
<figure>
<img src="https://raw.githubusercontent.com/Koorye/my-images/master/img/202309110923071.png" alt="image.png">
<figcaption aria-hidden="true">image.png</figcaption>
</figure>
<p>### VLM P re t ra in ing #### GLIP (CVPR 2022)
通过衡量图像区域与文本局部单词特征的相似度进行训练，为了加强匹配，还加入fusion模块促进两模态的融合。</p>
<figure>
<img src="https://s2.loli.net/2023/09/12/Qe32LHjYgJVONfo.jpg" alt="Qe32LHjYgJVONfo">
<figcaption aria-hidden="true">Qe32LHjYgJVONfo</figcaption>
</figure>
<h4 id="regionclip-cvpr-2021">RegionCLIP (CVPR 2021)</h4>
<p>CLIP首先在图像文本对上训练，之后在图像区域和类别描述对上训练，最后可用于细粒度的视觉任务。</p>
<figure>
<img src="https://s2.loli.net/2023/09/12/WmaKnirYEJb49PN.jpg" alt="WmaKnirYEJb49PN">
<figcaption aria-hidden="true">WmaKnirYEJb49PN</figcaption>
</figure>
<h4 id="filip-arxiv-2021">FILIP (arXiv 2021)</h4>
<p>衡量图像和文本局部特征之间的相似度，之后聚合成全局相似度进行训练。</p>
<figure>
<img src="https://s2.loli.net/2023/09/12/ZOjdXBJMTLE7AfW.jpg" alt="ZOjdXBJMTLE7AfW">
<figcaption aria-hidden="true">ZOjdXBJMTLE7AfW</figcaption>
</figure>
<h3 id="vlm-transfer">VLM Transfer</h3>
<h4 id="plot-iclr-2023">PLOT (ICLR 2023)</h4>
<p>计算视觉局部特征与文本特征的最优化分配矩阵，通过加权融合得到每个类别的分数。</p>
<figure>
<img src="https://s2.loli.net/2023/09/12/6zG5RmO1e7nCbwv.jpg" alt="6zG5RmO1e7nCbwv">
<figcaption aria-hidden="true">6zG5RmO1e7nCbwv</figcaption>
</figure>
<h4 id="tai-dpt-cvpr-2022">TaI-DPT (CVPR 2022)</h4>
<p>利用摘要文本对预训练后，图像通过编码得到全局和局部特征，其中全局特征与全局prompt编码的文本特征计算相似度，局部特征则与局部prompt编码的文本特征计算相似度后融合，最后两者加权得到分数。</p>
<figure>
<img src="https://s2.loli.net/2023/09/12/4MzwktVx57Q86eA.jpg" alt="4MzwktVx57Q86eA">
<figcaption aria-hidden="true">4MzwktVx57Q86eA</figcaption>
</figure>
<h4 id="dualcoop-arxiv-2022">DualCoOp (arXiv 2022)</h4>
<p>视觉局部特征与文本特征计算相似度，再通过softmax计算权重，最后加权融合。</p>
<figure>
<img src="https://s2.loli.net/2023/09/12/HZVU5Qx6Fti4Bru.jpg" alt="HZVU5Qx6Fti4Bru">
<figcaption aria-hidden="true">HZVU5Qx6Fti4Bru</figcaption>
</figure>
<h3 id="few-shot-object-detection">Few-shot Object Detection</h3>
<h4 id="detreg-cvpr-2023">DETReg (CVPR 2023)</h4>
<p>采用启发式方法在图像上挑选区域，并通过自监督模型为每个区域编码信息。训练一个检测器负责预测区域是否存在，位置及编码。</p>
<figure>
<img src="https://s2.loli.net/2023/09/13/Sx1h8lIpE5rjmUK.jpg" alt="Sx1h8lIpE5rjmUK">
<figcaption aria-hidden="true">Sx1h8lIpE5rjmUK</figcaption>
</figure>
<h2 id="局部特征融合">局部特征融合</h2>
<h3 id="few-shot-image-classification-1">Few-shot Image
Classification</h3>
<h4 id="ideme-net-cvpr-2019">IDeMe-Net (CVPR 2019)</h4>
<p>对于两张图像，预测每个region的权重，之后加权融合在一起，从而进行数据增强。</p>
<p><img src="https://raw.githubusercontent.com/Koorye/my-images/master/img/202309110930005.png"></p>
<h4 id="spot-and-learn-cvpr-2019">Spot and Learn (CVPR 2019)</h4>
<p>利用强化学习预测一张图像上的patch序列，这些patch送入一个rnn进行预测。</p>
<figure>
<img src="https://raw.githubusercontent.com/Koorye/my-images/master/img/202309110932170.png" alt="image.png">
<figcaption aria-hidden="true">image.png</figcaption>
</figure>
<h4 id="femn-cvpr-2019">FEMN (CVPR 2019)</h4>
<p>计算前/背景图像的相似度矩阵，之后拼接query图像与support图像的相似度矩阵并送入head预测分数。</p>
<figure>
<img src="https://raw.githubusercontent.com/Koorye/my-images/master/img/202309110936755.png" alt="image.png">
<figcaption aria-hidden="true">image.png</figcaption>
</figure>
<h4 id="attention-network-cvpr-2017">Attention Network (CVPR 2017)</h4>
<p>计算词向量与视觉局部特征之间的相似度作为mask。</p>
<figure>
<img src="https://s2.loli.net/2023/09/12/i7YrZ28T64akH9g.jpg" alt="i7YrZ28T64akH9g">
<figcaption aria-hidden="true">i7YrZ28T64akH9g</figcaption>
</figure>
<h4 id="cross-attention-network-neurips-2017">Cross Attention Network
(NeurIPS 2017)</h4>
<p>计算查询与支持特征局部特征的两两相似度(<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="23.171ex" height="2.009ex" role="img" focusable="false" viewBox="0 -694 10241.7 888"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="mo" transform="translate(1036.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(2092.6,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(3192.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(4193,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(5071,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(5515.7,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(6671.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(7727.2,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mo" transform="translate(8525.4,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(9525.7,0)"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g></g></g></svg></mjx-container></span>)，之后相似度矩阵R通过自预测参数的卷积进一步融合得到mask，将其应用到原特征上。</p>
<figure>
<img src="https://s2.loli.net/2023/09/12/VCxve6X8y3I4gqP.jpg" alt="VCxve6X8y3I4gqP">
<figcaption aria-hidden="true">VCxve6X8y3I4gqP</figcaption>
</figure>
<h3 id="vlm-pretraining">VLM Pretraining</h3>
<h4 id="hiclip-iclr-2023">HICLIP (ICLR 2023)</h4>
<p>transformer在各层前向过程中进行自适应的分组和分层。</p>
<figure>
<img src="https://s2.loli.net/2023/09/12/lLqcfej2KHTvIwQ.jpg" alt="lLqcfej2KHTvIwQ">
<figcaption aria-hidden="true">lLqcfej2KHTvIwQ</figcaption>
</figure>
<h3 id="vlm-transfer-1">VLM Transfer</h3>
<h4 id="calip-aaai-2023">CALIP (AAAI 2023)</h4>
<p>通过一个无需参数的注意力机制进行融合，利用融合后特征进行度量。</p>
<figure>
<img src="https://s2.loli.net/2023/09/12/gvhWBym3nRQ9NLT.jpg" alt="gvhWBym3nRQ9NLT">
<figcaption aria-hidden="true">gvhWBym3nRQ9NLT</figcaption>
</figure>
<h4 id="sp-cvpr-2023">SP (CVPR 2023)</h4>
<p>通过空间和通过交互对每个patch token进行融合，前者即将文本token与patch
token拼接在一起作attention，后者即将文本token与patch
token的均值拼接在一起通过MLP进行融合。</p>
<figure>
<img src="https://s2.loli.net/2023/09/12/1fltvN5suihwQTa.jpg" alt="1fltvN5suihwQTa">
<figcaption aria-hidden="true">1fltvN5suihwQTa</figcaption>
</figure>
<h4 id="denseclip-cvpr-2023">DenseCLIP (CVPR 2023)</h4>
<p>文本特征与视觉局部特征计算相似度得到分数图，将分数图送入解码器来预测分割图。</p>
<figure>
<img src="https://s2.loli.net/2023/09/12/nftURovFOjKWec8.jpg" alt="nftURovFOjKWec8">
<figcaption aria-hidden="true">nftURovFOjKWec8</figcaption>
</figure>
<h4 id="pleor-cvpr-2023">PLEor (CVPR 2023)</h4>
<p>图像通过卷积网络再放缩回图像尺寸得到图像prompt，该prompt反映了每个像素包含类别特定特征的比例。于是prompt与原图相乘得到去除无关特征的图像，1-prompt与原图相乘得到只有无关特征的图像，两者进行编码得到特征，前者与对应类别的文本特征相逼近，后者与所有类别特征相远离。</p>
<figure>
<img src="https://s2.loli.net/2023/09/12/rax18qOQ4UAmVSf.jpg" alt="rax18qOQ4UAmVSf">
<figcaption aria-hidden="true">rax18qOQ4UAmVSf</figcaption>
</figure>
<h3 id="few-shot-object-detection-1">Few-shot Object Detection</h3>
<h4 id="attention-rpn-cvpr-2020">Attention RPN (CVPR 2020)</h4>
<p>将支持集平均特征作为卷积核参数，在查询集局部特征上进行逐元素卷积进行融合。</p>
<figure>
<img src="https://s2.loli.net/2023/09/13/bERlLcf2PrM5IYh.jpg" alt="bERlLcf2PrM5IYh">
<figcaption aria-hidden="true">bERlLcf2PrM5IYh</figcaption>
</figure>
<h4 id="drd-cvpr-2021">DRD (CVPR 2021)</h4>
<p>通过co-attention机制进行查询与支持特征的深度融合。</p>
<figure>
<img src="https://s2.loli.net/2023/09/13/FSB4ucNlwLM6YIR.jpg" alt="FSB4ucNlwLM6YIR">
<figcaption aria-hidden="true">FSB4ucNlwLM6YIR</figcaption>
</figure>
<h4 id="dana-tmm-2021">DAnA (TMM 2021)</h4>
<p>特征首先通过通道自注意力增强，之后查询与支持特征作attention并于支持特征自身的变换相加，最后注意力图与支持特征相乘得到每个空间位置的支持向量，并在多个shot之间求均值。</p>
<figure>
<img src="https://s2.loli.net/2023/09/13/orRwxMdVfIazjuW.jpg" alt="orRwxMdVfIazjuW">
<figcaption aria-hidden="true">orRwxMdVfIazjuW</figcaption>
</figure>
<h4 id="meta-faster-rcnn-aaai-2022">Meta Faster-RCNN (AAAI 2022)</h4>
<p>支持和查询特征首先计算亲和力（即相似度）矩阵，与支持特征相乘以进行特征对齐，之后亲和力矩阵按行求和得到mask，与支持和查询特征相乘以保留前景。</p>
<figure>
<img src="https://s2.loli.net/2023/09/13/3YGj6LqMdHuNPIc.jpg" alt="3YGj6LqMdHuNPIc">
<figcaption aria-hidden="true">3YGj6LqMdHuNPIc</figcaption>
</figure>
<h4 id="fct-cvpr-2022">FCT (CVPR 2022)</h4>
<p>采用cross transformer结构实现支持和查询特征的深入融合。</p>
<figure>
<img src="https://s2.loli.net/2023/09/13/qY3OW1wQ9z64JVa.jpg" alt="qY3OW1wQ9z64JVa">
<figcaption aria-hidden="true">qY3OW1wQ9z64JVa</figcaption>
</figure>
<h4 id="pa-bovw-eccv-2022">PA-BoVW (ECCV 2022)</h4>
<p>利用自监督方法训练一个词袋（包含若干原型），之后利用词袋的每个原型与检测器backbone特征与自监督特征计算相似度得到相似度图，对两者的相似度图进行蒸馏。</p>
<figure>
<img src="https://s2.loli.net/2023/09/13/adqbSX5xmv8UugT.jpg" alt="adqbSX5xmv8UugT">
<figcaption aria-hidden="true">adqbSX5xmv8UugT</figcaption>
</figure>
<h2 id="其他方法">其他方法</h2>
<h3 id="cme-cvpr-2021">CME (CVPR 2021)</h3>
<p>在finetune过程中逐渐屏蔽图像梯度最大的区域进行扰动，从而增强数据。</p>
<figure>
<img src="https://s2.loli.net/2023/09/13/IelVBM5vhTpwYUC.jpg" alt="IelVBM5vhTpwYUC">
<figcaption aria-hidden="true">IelVBM5vhTpwYUC</figcaption>
</figure>
<h1 id="总结">总结</h1>
<p>局部特征的利用可以分为匹配和融合两大类。前者的目标是设计某种度量方式进行两种样本或模态之间的匹配，从而实现分类；后者的目标是使得两种样本或模态的特征按需求进行融合，更好馈送到之后的任务。</p>
<p><strong>局部特征匹配</strong>
这类方法往往提出一些人工设计的度量指标（如协方差、BDC距离、EM距离等），代替简单余弦相似度；还有的方法提出可学习的模块用于匹配，例如对每个region单独进行分类后聚合。究其根本，度量方式可以分为：
- region-region 这类方法对每个region单独打分，之后再进行聚合作为总分。 -
set-set
这类方法直接将所有region视为一个集合，通过一些度量方式进行集合到集合的直接打分。</p>
<p><strong>局部特征融合</strong>
这类方法通过一些特定的结构，实现局部特征自身，或是两个样本或模态的局部特征之间的融合。
-
对于局部特征自身的融合来说，一些分层或循环结构被采用，用于提取coarse-to-refine、low-to-high的特征。
-
对于跨样本或模态的局部特征融合来说，最主流的做法是类似attention或transformer的结构，如concat+attention、cross-attention、co-attention、多层cross-attention+ffn等，几乎是attention的各种变体。</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/blog/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"># 深度学习</a>
              <a href="/blog/tags/%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0/" rel="tag"># 小样本学习</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/blog/2023/08/21/2023-08-21%20How%20to%20Learn%20Meta%20Knowledge%20in%20Few-shot%20Learning/" rel="prev" title="小样本学习中的元知识学习方法">
      <i class="fa fa-chevron-left"></i> 小样本学习中的元知识学习方法
    </a></div>
      <div class="post-nav-item">
    <a href="/blog/2023/09/27/2023-09-27%20Details%20of%20Set-to-set%20Region%20Feature%20Matching%20Methods/" rel="next" title="集合到集合区域特征匹配方法详解">
      集合到集合区域特征匹配方法详解 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%96%B9%E6%B3%95"><span class="nav-number">1.</span> <span class="nav-text">方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B1%80%E9%83%A8%E7%89%B9%E5%BE%81%E5%8C%B9%E9%85%8D"><span class="nav-number">1.1.</span> <span class="nav-text">局部特征匹配</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#few-shot-image-classification"><span class="nav-number">1.1.1.</span> <span class="nav-text">Few-shot Image
Classification</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#deepbdc-cvpr-2022"><span class="nav-number">1.1.1.1.</span> <span class="nav-text">DeepBDC (CVPR 2022)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#deepemd-cvpr-2020"><span class="nav-number">1.1.1.2.</span> <span class="nav-text">DeepEMD (CVPR 2020)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#regionclip-cvpr-2021"><span class="nav-number">1.1.1.3.</span> <span class="nav-text">RegionCLIP (CVPR 2021)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#filip-arxiv-2021"><span class="nav-number">1.1.1.4.</span> <span class="nav-text">FILIP (arXiv 2021)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#vlm-transfer"><span class="nav-number">1.1.2.</span> <span class="nav-text">VLM Transfer</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#plot-iclr-2023"><span class="nav-number">1.1.2.1.</span> <span class="nav-text">PLOT (ICLR 2023)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#tai-dpt-cvpr-2022"><span class="nav-number">1.1.2.2.</span> <span class="nav-text">TaI-DPT (CVPR 2022)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#dualcoop-arxiv-2022"><span class="nav-number">1.1.2.3.</span> <span class="nav-text">DualCoOp (arXiv 2022)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#few-shot-object-detection"><span class="nav-number">1.1.3.</span> <span class="nav-text">Few-shot Object Detection</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#detreg-cvpr-2023"><span class="nav-number">1.1.3.1.</span> <span class="nav-text">DETReg (CVPR 2023)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B1%80%E9%83%A8%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88"><span class="nav-number">1.2.</span> <span class="nav-text">局部特征融合</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#few-shot-image-classification-1"><span class="nav-number">1.2.1.</span> <span class="nav-text">Few-shot Image
Classification</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#ideme-net-cvpr-2019"><span class="nav-number">1.2.1.1.</span> <span class="nav-text">IDeMe-Net (CVPR 2019)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#spot-and-learn-cvpr-2019"><span class="nav-number">1.2.1.2.</span> <span class="nav-text">Spot and Learn (CVPR 2019)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#femn-cvpr-2019"><span class="nav-number">1.2.1.3.</span> <span class="nav-text">FEMN (CVPR 2019)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#attention-network-cvpr-2017"><span class="nav-number">1.2.1.4.</span> <span class="nav-text">Attention Network (CVPR 2017)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#cross-attention-network-neurips-2017"><span class="nav-number">1.2.1.5.</span> <span class="nav-text">Cross Attention Network
(NeurIPS 2017)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#vlm-pretraining"><span class="nav-number">1.2.2.</span> <span class="nav-text">VLM Pretraining</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#hiclip-iclr-2023"><span class="nav-number">1.2.2.1.</span> <span class="nav-text">HICLIP (ICLR 2023)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#vlm-transfer-1"><span class="nav-number">1.2.3.</span> <span class="nav-text">VLM Transfer</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#calip-aaai-2023"><span class="nav-number">1.2.3.1.</span> <span class="nav-text">CALIP (AAAI 2023)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#sp-cvpr-2023"><span class="nav-number">1.2.3.2.</span> <span class="nav-text">SP (CVPR 2023)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#denseclip-cvpr-2023"><span class="nav-number">1.2.3.3.</span> <span class="nav-text">DenseCLIP (CVPR 2023)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#pleor-cvpr-2023"><span class="nav-number">1.2.3.4.</span> <span class="nav-text">PLEor (CVPR 2023)</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#few-shot-object-detection-1"><span class="nav-number">1.2.4.</span> <span class="nav-text">Few-shot Object Detection</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#attention-rpn-cvpr-2020"><span class="nav-number">1.2.4.1.</span> <span class="nav-text">Attention RPN (CVPR 2020)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#drd-cvpr-2021"><span class="nav-number">1.2.4.2.</span> <span class="nav-text">DRD (CVPR 2021)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#dana-tmm-2021"><span class="nav-number">1.2.4.3.</span> <span class="nav-text">DAnA (TMM 2021)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#meta-faster-rcnn-aaai-2022"><span class="nav-number">1.2.4.4.</span> <span class="nav-text">Meta Faster-RCNN (AAAI 2022)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#fct-cvpr-2022"><span class="nav-number">1.2.4.5.</span> <span class="nav-text">FCT (CVPR 2022)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#pa-bovw-eccv-2022"><span class="nav-number">1.2.4.6.</span> <span class="nav-text">PA-BoVW (ECCV 2022)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%B6%E4%BB%96%E6%96%B9%E6%B3%95"><span class="nav-number">1.3.</span> <span class="nav-text">其他方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#cme-cvpr-2021"><span class="nav-number">1.3.1.</span> <span class="nav-text">CME (CVPR 2021)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">2.</span> <span class="nav-text">总结</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="吴世涵"
      src="/blog/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">吴世涵</p>
  <div class="site-description" itemprop="description">来自电子科技大学(UESTC)计算机科学与工程学院的硕士研究生</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/blog/archives/">
        
          <span class="site-state-item-count">90</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/blog/categories/">
          
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/blog/tags/">
          
        <span class="site-state-item-count">61</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Koorye" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Koorye" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:shihan.wu.koorye@outlook.com" title="E-Mail → mailto:shihan.wu.koorye@outlook.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      我的链接
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://koorye.github.io/" title="https:&#x2F;&#x2F;Koorye.github.io">个人主页</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://github.com/Koorye" title="https:&#x2F;&#x2F;github.com&#x2F;Koorye" rel="noopener" target="_blank">Github</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://scholar.google.com/citations?hl=en&user=7VCaV5EAAAAJ" title="https:&#x2F;&#x2F;scholar.google.com&#x2F;citations?hl&#x3D;en&amp;user&#x3D;7VCaV5EAAAAJ" rel="noopener" target="_blank">谷歌学术</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://dblp.org/pid/132/9517-1.html" title="https:&#x2F;&#x2F;dblp.org&#x2F;pid&#x2F;132&#x2F;9517-1.html" rel="noopener" target="_blank">dblp</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">吴世涵</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">516k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">7:49</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/blog/lib/anime.min.js"></script>
  <script src="/blog/lib/velocity/velocity.min.js"></script>
  <script src="/blog/lib/velocity/velocity.ui.min.js"></script>

<script src="/blog/js/utils.js"></script>

<script src="/blog/js/motion.js"></script>


<script src="/blog/js/schemes/muse.js"></script>


<script src="/blog/js/next-boot.js"></script>




  




  
<script src="/blog/js/local-search.js"></script>











<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js', () => {
    mermaid.initialize({
      theme    : 'default',
      logLevel : 3,
      flowchart: { curve     : 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 }
    });
  }, window.mermaid);
}
</script>


  

  

  

</body>
</html>
