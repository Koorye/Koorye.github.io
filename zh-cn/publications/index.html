<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>发表论文 | 吴世涵的主页</title>
    <meta name="description" content="我的学术主页">
    <link rel="icon" href="/zh-cn/logo.png">
    
    <link rel="preload" href="/zh-cn/assets/css/0.styles.780e8982.css" as="style"><link rel="preload" href="/zh-cn/assets/js/app.0bf4e553.js" as="script"><link rel="preload" href="/zh-cn/assets/js/2.705274af.js" as="script"><link rel="preload" href="/zh-cn/assets/js/10.f07ac77e.js" as="script"><link rel="preload" href="/zh-cn/assets/js/6.b35d7dce.js" as="script"><link rel="prefetch" href="/zh-cn/assets/js/11.7d44622e.js"><link rel="prefetch" href="/zh-cn/assets/js/12.5d8c0c77.js"><link rel="prefetch" href="/zh-cn/assets/js/13.f55ba89c.js"><link rel="prefetch" href="/zh-cn/assets/js/14.89757103.js"><link rel="prefetch" href="/zh-cn/assets/js/15.1ea84ce6.js"><link rel="prefetch" href="/zh-cn/assets/js/16.cf9fee51.js"><link rel="prefetch" href="/zh-cn/assets/js/3.66d091c3.js"><link rel="prefetch" href="/zh-cn/assets/js/4.4d1b0181.js"><link rel="prefetch" href="/zh-cn/assets/js/5.ae03c7e5.js"><link rel="prefetch" href="/zh-cn/assets/js/7.882ef9ff.js"><link rel="prefetch" href="/zh-cn/assets/js/8.06918222.js"><link rel="prefetch" href="/zh-cn/assets/js/9.d92c6893.js">
    <link rel="stylesheet" href="/zh-cn/assets/css/0.styles.780e8982.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar publicationnpm-page"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/zh-cn/" class="home-link router-link-active"><!----> <span class="site-name">吴世涵的主页</span></a> <div class="links"><!----> <nav class="nav-links can-hide"><div class="nav-item"><a href="/zh-cn/" class="nav-link">主页</a></div><div class="nav-item"><a href="/zh-cn/publications/" class="nav-link router-link-exact-active router-link-active">发表论文</a></div><div class="nav-item"><a href="/zh-cn/about/" class="nav-link">关于我</a></div><div class="nav-item"><a href="https://Koorye.github.io/blog" target="_blank" rel="noopener noreferrer" class="nav-link external">
  博客
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div><div class="nav-item"><a href="https://Koorye.github.io" target="_blank" rel="noopener noreferrer" class="nav-link external">
  English Homepage
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/zh-cn/" class="nav-link">主页</a></div><div class="nav-item"><a href="/zh-cn/publications/" class="nav-link router-link-exact-active router-link-active">发表论文</a></div><div class="nav-item"><a href="/zh-cn/about/" class="nav-link">关于我</a></div><div class="nav-item"><a href="https://Koorye.github.io/blog" target="_blank" rel="noopener noreferrer" class="nav-link external">
  博客
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div><div class="nav-item"><a href="https://Koorye.github.io" target="_blank" rel="noopener noreferrer" class="nav-link external">
  English Homepage
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <!----></nav>  <!----> </aside> <main class="page"> <div class="theme-default-content content__default"><h2 id="发表论文">发表论文</h2> <div class="md-detail-card"><div class="card-content"><p><strong>Policy Contrastive Decoding for Robotic Foundation Models</strong></p> <p><strong>Shihan Wu</strong>*, Ji Zhang*, Xu Luo, Junlin Xie, Jingkuan Song, Heng Tao Shen, Lianli Gao</p> <p>机器人基础模型，或通用机器人策略，具有实现灵活、通用和灵巧机器人系统的巨大潜力。尽管它们取得了进展，但我们的实验证明，现有的机器人策略容易从预训练轨迹中学习到<strong>虚假相关性</strong>，从而影响其在训练数据范围之外的泛化能力。</p> <p>为了解决这个问题，我们提出了一种新颖的<strong>策略对比解码</strong>（PCD）方法，通过对比源视觉输入和对象遮蔽视觉输入的动作概率分布，将机器人策略的注意力重定向到与对象相关的视觉线索上。作为一种<strong>无需训练</strong>的方法，我们的PCD可以作为<strong>插件</strong>来改进不同类型的机器人策略，而无需微调或访问模型权重。</p> <p>我们在三个开源机器人策略上进行了广泛的实验，包括自回归策略OpenVLA和基于扩散的策略Octo和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>π</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\pi_0</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">π</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">0</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>。实验结果证明了PCD在模拟和现实环境中的灵活性和有效性，例如，PCD在模拟环境中提高了最先进的策略<strong>8%</strong>，在现实环境中提高了<strong>108%</strong>。</p> <p><a href="https://koorye.github.io/proj/PCD" target="_blank" rel="noopener noreferrer">[项目主页]<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> <a href="https://arxiv.org/pdf/2505.13255" target="_blank" rel="noopener noreferrer">[PDF]<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> <a href="https://arxiv.org/abs/2505.13255" target="_blank" rel="noopener noreferrer">[arXiv]<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> <a href="https://github.com/Koorye/PCD" target="_blank" rel="noopener noreferrer">[代码]<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><img src="https://img.shields.io/github/stars/Koorye/PCD?style=for-the-badge&amp;labelColor=%23eeeeee" alt="GitHub Repo stars"></p></div> <div class="card-image"><img src="/zh-cn/pubs/pcd_detail.png" alt></div></div> <div class="md-detail-card"><div class="card-content"><p><strong>InSpire: Vision-Language-Action Models with Intrinsic Spatial Reasoning</strong></p> <p>Ji Zhang*, <strong>Shihan Wu</strong>*, Xu Luo, Hao Wu, Lianli Gao, Heng Tao Shen, Jingkuan Song</p> <p>利用预训练的视觉语言模型（VLMs）将语言指令和视觉观察映射到原始低级动作，视觉语言动作模型（VLAs）有望实现通用机器人系统。尽管取得了进展，但现有的VLA往往会将与任务无关的视觉特征与动作<strong>虚假关联</strong>，从而限制了其在训练数据之外的泛化能力。</p> <p>为了解决这个挑战，我们提出了<strong>内在空间推理</strong>（InSpire），这是一种简单而有效的方法，通过增强VLA的空间推理能力来减轻虚假相关性的负面影响。具体而言，InSpire通过在语言指令前添加问题“[对象]相对于机器人处于哪个方向？”来将VLA的注意力重定向到与任务相关的因素，并将答案“右/左/上/下/前/后/抓取”和预测动作与地面真实值对齐。</p> <p>值得注意的是，InSpire可以作为<strong>插件</strong>来增强现有的自回归VLA，无需额外的训练数据或与其他大型模型交互。模拟和现实环境中的广泛实验结果证明了我们方法的有效性和灵活性。</p> <p><a href="https://koorye.github.io/proj/Inspire" target="_blank" rel="noopener noreferrer">[项目主页]<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> <a href="https://arxiv.org/pdf/2412.11509" target="_blank" rel="noopener noreferrer">[PDF]<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> <a href="https://arxiv.org/abs/2412.11509" target="_blank" rel="noopener noreferrer">[arXiv]<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> <a href="https://github.com/Koorye.SkipTuning" target="_blank" rel="noopener noreferrer">[代码]<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><img src="https://img.shields.io/github/stars/Koorye/InSpire?style=for-the-badge&amp;labelColor=%23eeeeee" alt="GitHub Repo stars"></p></div> <div class="card-image"><img src="/zh-cn/pubs/inspire_detail.png" alt></div></div> <div class="md-detail-card"><div class="card-content"><p><strong>[CVPR 2025] Skip Tuning: Pre-trained Vision-Language Models are Effective and Efficient Adapters Themselves</strong></p> <p><strong>Shihan Wu</strong>, Ji Zhang, Pengpeng Zeng, Lianli Gao, Jingkuan Song, Heng Tao Shen</p> <p>提示调优（PT）长期以来被认为是将大型预训练视觉语言模型（VLMs）转移到下游任务的有效和高效范式，通过学习一小组上下文向量。然而，在这项工作中，我们揭示了在学习上下文向量时冻结VLMs的参数既<strong>不能促进预训练知识的可转移性</strong>，也<strong>不能显著提高内存和时间效率</strong>。</p> <p>经过进一步调查，我们发现减少全量微调（FT）基线的<strong>特征梯度传播流的长度和宽度</strong>是实现有效和高效知识转移的关键。基于此，我们提出了<strong>Skip Tuning</strong>，这是一种适应VLMs到下游任务的新范式。与现有的PT或基于适配器的方法不同，跳过调优在FT基线上应用了层级跳过（LSkip）和类级跳过（CSkip），而不引入额外的上下文向量或适配器模块。</p> <p>广泛的实验结果表明，我们的跳过调优在各种基准测试中表现出<strong>优越的有效性和效率</strong>，超过了PT和基于适配器的方法。</p> <p><a href="https://arxiv.org/pdf/2412.11509" target="_blank" rel="noopener noreferrer">[PDF]<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> <a href="https://arxiv.org/abs/2412.11509" target="_blank" rel="noopener noreferrer">[arXiv]<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> <a href="https://github.com/Koorye/SkipTuning" target="_blank" rel="noopener noreferrer">[代码]<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><img src="https://img.shields.io/github/stars/Koorye/SkipTuning?style=for-the-badge&amp;labelColor=%23eeeeee" alt="GitHub Repo stars"></p></div> <div class="card-image"><img src="/zh-cn/pubs/skiptuning_detail.png" alt></div></div> <div class="md-detail-card"><div class="card-content"><p><strong>Rethinking Conditional Prompt Tuning for Vision-Language Models</strong></p> <p>Ji Zhang, <strong>Shihan Wu</strong>, Pengpeng Zeng, Lianli Gao, Jingkuan Song, Heng Tao Shen</p> <p>提示调优在将大型视觉语言预训练模型（VLPMs）适应到各种下游任务方面表现出色。尽管前景广阔，但现有的提示学习方法往往难以克服<strong>基础-新任务权衡</strong>（BNT）问题，即当VLPMs更好地适应基础（或目标）任务时，它们对新任务的泛化能力会降低。最近的条件提示学习工作通过用动态的视觉图像信息（VII）条件提示替换静态提示来解决这个问题，在一定程度上提高了模型对新任务的泛化能力。</p> <p>在这项工作中，我们发现现有条件提示调优方法存在一个关键问题：新任务上的性能提升并没有受益于注入到提示中的VII。事实上，即使是随机噪声条件的提示也可以超过VII条件的对应物。进一步分析发现，学习基于文本类信息（TCI）的动态提示是解决提示调优中的BNT问题的关键。基于此，我们提出了<strong>类自适应提示调优</strong>（CaPT），它通过从基础任务类中学习TCI条件的提示，使调优模型能够快速适应新类。</p> <p>值得注意的是，我们的CaPT与现有的无条件提示调优方法是正交的，可以作为<strong>插件</strong>来增强它们，而几乎不增加额外的计算成本。在多个数据集上的广泛实验表明了CaPT的强大<strong>灵活性</strong>和<strong>有效性</strong>。CaPT在基础到新任务泛化、跨数据集泛化和跨领域泛化设置中持续提高了广泛的提示调优方法的性能。</p> <p><a href="https://github.com/Koorye/CaPT" target="_blank" rel="noopener noreferrer">[代码]<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><img src="https://img.shields.io/github/stars/Koorye/CaPT?style=for-the-badge&amp;labelColor=%23eeeeee" alt="GitHub Repo stars"></p></div> <div class="card-image"><img src="/zh-cn/pubs/capt_detail.png" alt></div></div> <div class="md-detail-card"><div class="card-content"><p><strong>[CVPR 2024] DePT: Decoupled Prompt Tuning</strong></p> <p>Ji Zhang*, <strong>Shihan Wu</strong>*, Lianli Gao, Heng Tao Shen, Jingkuan Song</p> <p>提示调优在将大型视觉语言预训练模型适应到下游任务方面取得了巨大的成功。已经提出了大量方法来解决<strong>基础-新任务权衡</strong>（BNT）困境，即适应后的模型对基础（或目标）任务的泛化越好，对新任务的泛化就越差，反之亦然。尽管如此，BNT问题仍然远未解决，其基本机制也不清楚。</p> <p>在这项工作中，我们通过提出<strong>解耦提示调优</strong>（DePT）来填补这一空白，这是第一个从特征解耦的角度解决BNT问题的框架。具体而言，通过对基础和新任务的学习特征进行深入分析，我们观察到BNT源于通道偏置问题，即大多数特征通道被基础特定知识占据，导致对新任务重要的任务共享知识崩溃。为了解决这个问题，DePT在提示调优过程中将基础特定知识从特征通道中解耦到一个独立的特征空间，从而最大限度地保留原始特征空间中的任务共享知识，以实现对新任务更好的零样本泛化。</p> <p>DePT与现有的提示调优方法是正交的，因此可以解决所有方法的BNT问题。在11个数据集上的广泛实验表明了DePT的强大<strong>灵活性</strong>和<strong>有效性</strong>。</p> <p><a href="https://arxiv.org/pdf/2309.07439" target="_blank" rel="noopener noreferrer">[PDF]<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> <a href="https://arxiv.org/abs/2309.07439" target="_blank" rel="noopener noreferrer">[arXiv]<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> <a href="https://github.com/Koorye/DePT" target="_blank" rel="noopener noreferrer">[代码]<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><img src="https://img.shields.io/github/stars/Koorye/DePT?style=for-the-badge&amp;labelColor=%23eeeeee" alt="GitHub Repo stars"></p></div> <div class="card-image"><img src="/zh-cn/pubs/dept_detail.png" alt></div></div></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/zh-cn/assets/js/app.0bf4e553.js" defer></script><script src="/zh-cn/assets/js/2.705274af.js" defer></script><script src="/zh-cn/assets/js/10.f07ac77e.js" defer></script><script src="/zh-cn/assets/js/6.b35d7dce.js" defer></script>
  </body>
</html>
